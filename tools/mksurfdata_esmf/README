=======
Purpose
=======
This tool is intended to generate fsurdat files (surface datasets) for the
CTSM. It can generate global, regional, and single-point fsurdat files, as long
as a mesh file is available for the grid.

The subset_data tool allows users to make fsurdat files from existing fsurdat
files when a mesh file is unavailable. Generally, users should consider the
subset_data tool for generating regional and single-point fsurdat files.

===================
Build Requirements:
===================

mksurfdata_esmf is a distributed memory parallel program (using Message Passing
Interface -- MPI) that utilizes both ESMF (Earth System Modelling Framework)
for regridding as well as PIO (Parallel I/O) and NetCDF output. As
such, libraries must be built for the following:

1) MPI
2) NetCDF
3) PIO
4) ESMF

In addition for the build: python, bash-shell, CMake and GNU-Make are required

These libraries need to be built such that they can all work together in the
same executable. Hence, the above order may be required in building them.

=========================================
Use cime to manage the build requirements
=========================================

For users working on cime machines you can use the build script to build the
tool. On other machines you'll need to do a port to cime and tell how to build
for that machine. That's talked about in the cime documentation.
And you'll have to make some modifications to the build script.

https://github.com/ESMCI/cime/wiki/Porting-Overview

Machines that already run CTSM or CESM have been ported to cime. So if you can
run the model on your machine, you will be able to build the tool there.

To get a list of the machines that have been ported to cime: 

cd ../../cime/scripts  # assumes we are in tools/mksurfdata_esmf
./query_config --machines

NOTE:
In addition to having a port to cime, the machine also needs to have PIO built
and able to be referenced with the env variable PIO which will need to be in
the porting instructions for the machine. Currently an independent PIO library
is not available on cime ported machines.

=======================
Building the executable (working in tools/mksurfdata_esmf)
=======================

# Before starting, be sure that you have run
> ./manage_externals/checkout_externals
# because without it we have come across strange behavior, such as transient
# file generation (1850-2015) that aborts in the 1870s for no apparent reason.
> ./gen_mksurfdata_build.sh      # For machines with a cime build
# Note: The pio_iotype value gets set and written to a simple .txt file
# by this build script. The value depends on your machine. If not running
# on cheyenne, casper, izumi, or hobart, you may need to update this, though
# a default value does get set for other machines.

=======================
Running for a single submission:
=======================
# Work in the ctsm_pylib environment, which requires the following steps:
> module unload python; module load conda
> cd ../..; ./py_env_create
> conda activate ctsm_pylib; cd tools/mksurfdata_esmf
# to generate your target namelist:
> ./gen_mksurfdata_namelist --help
# for example try --res 1.9x2.5 --start-year 1850 --end-year 1850:
> ./gen_mksurfdata_namelist --res <resolution> --start-year <year1> --end-year <year2>
# IF FILES ARE MISSING FROM /inputdata, a target namelist will be generated
# but with a generic name and with warning to run ./download_input_data next.
# IF A SMALLER SET OF FILES IS STILL MISSING AFTER RUNNING ./download_input_data
# and rerunning ./gen_mksurfdata_namelist, then rerun
# ./gen_mksurfdata_namelist with --vic selected (and iteratively additional
# options if still necessary) and rerun ./download_input_data until
# ./gen_mksurfdata_namelist finds all files.

# to generate your target jobscript (again --help for instructions):
> ./gen_mksurfdata_jobscript_single --number-of-nodes 2 --tasks-per-node 128 --namelist-file target.namelist
> qsub mksurfdata_jobscript_single
# Read note about regional grids below.

=======================
Running for the generation of multiple datasets
=======================
# Work in the ctsm_pylib environment, as explained in earlier section.
# gen_mksurfdata_jobscript_multi runs ./gen_mksurfdata_namelist for you
> ./gen_mksurfdata_jobscript_multi --help
> ./gen_mksurfdata_jobscript_multi --number-of-nodes 2 --scenario global-present
> qsub mksurfdata_jobscript_multi
# If you are looking to generate all (or a large number of) the datasets or the
# single-point (1x1) datasets, you are best off using the Makefile. For example
> make all  # ...or
> make all-subset

================
NOTES
================

------------------------------------
slevis HAS LISTED ISSUES ENCOUNTERED
------------------------------------
0) New 30-sec raw data for soil texture fails. Try requesting more mem.
1) Soil color & texture and ag fire peak month outputs too high in .log
   TODO? Change frac_o from always 1.
2) Pct lake has chged in the .log bc the old diagnostic omitted mask_i frac_o
3) Slope, stddev have chged in the .log bc the old diag. used frac_o

--------------------------------------
ALL raw dataset .nc FILES MUST BE cdf5
--------------------------------------
> nccopy -k cdf5 oldfile newfile
-------------------------------------------------------------
LAI raw dataset .nc FILE MUST HAVE "unlimited" time dimension
-------------------------------------------------------------
ncks --mk_rec_dmn time file_with_time_equals_12.nc -o file_with_time_unlimited.nc

--------------------------------------------------------
Override options removed that need to be placed in fsurdat_modifier
and/or subset_data:
--------------------------------------------------------
--soil_clay --soil_sand for setting to these values everywhere
--all_urban = .true.
Normalize so that sum(urban_classes_o(n,:)) = 100 for all n, even for grid
cells where pcturb_o(n) = 0 (in the case where pcturb_o(n) = 0, come up with an
arbitrary assignment of urban into the different classes).
See comments in the normalize_urbn_by_tot subroutine for how urban_classes_o is
determined when the total % urban is 0, according to the input data.
